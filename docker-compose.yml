version: "3.8"

services:
  galore:
    build:
      context: .
      dockerfile: ./docker/Dockerfile
    platform: linux/amd64 
    runtime: nvidia
    environment:
      - WANDB_MODE=offline
    volumes:
      - ./:/code 
    command: >
      torchrun --standalone --nproc_per_node 1 torchrun_main.py
      --model_config configs/llama_7b.json
      --lr 0.005
      --galore_scale 0.25
      --rank 1024
      --update_proj_gap 500
      --batch_size 16
      --total_batch_size 512
      --activation_checkpointing
      --num_training_steps 150000
      --warmup_steps 15000
      --weight_decay 0
      --grad_clipping 1.0
      --dtype bfloat16
      --eval_every 1000
      --single_gpu
      --optimizer galore_adamw8bit_per_layer
      --log_level DEBUG
